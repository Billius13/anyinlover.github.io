<p>在前面的混合高斯模型中，我们常常假定我们有充足的样本去发现数据的内在结构。也就是样本数m远远大于特征数n。</p>

<p>现在考虑<script type="math/tex">n \gg n</script>的情况，在这样的条件下，单高斯模型都无法拟合，更不论混合高斯模型了。根据最大似然估计，高斯模型的拟合参数如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
\mu &= \frac {1} {m} \sum_{i=1}^m x^{(i)} \\
\Sigma &= \frac {1} {m} \sum_{i=1}^m (x^{(i)}-\mu) (x^{(i)}-\mu)^T
\end{align}
 %]]></script>

<p>我们会发现<script type="math/tex">\Sigma</script>是奇异阵，<script type="math/tex">\Sigma^{-1}</script>不存在。这样就无法计算模型的密度函数了。</p>

<p>进一步讲，要通过最大似然估计来拟合高斯模型，必须让m远大于n，才能有比较好的结果。</p>

<p>那么我们如何解决这个样本数不足的问题呢？</p>

<h2 id="sigma">限制<script type="math/tex">\Sigma</script></h2>
<p>如果我们没有足够的数据来拟合一个协方差矩阵，我们可以为其添加一些限制。比如考虑协方差矩阵是对角的，也就是特征间是相互独立的，在这种情况下：</p>

<script type="math/tex; mode=display">\Sigma_{jj} = \frac {1} {m} \sum_{i=1}^m (x_j^{(i)}-\mu_j)^2</script>

<p>二元高斯分布在平面的投影是个椭圆，对角阵意味着椭圆轴线与坐标轴平行。</p>

<p>进一步，我们还能控制<script type="math/tex">\Sigma</script>不仅是对角的，而且对角元素相同。<script type="math/tex">\Sigma= \sigma^2 I</script>，<script type="math/tex">\sigma^2</script>可以通过最大似然估计得到：</p>

<script type="math/tex; mode=display">\sigma^2 = \frac {1}{mn} \sum_{j=1}^n \sum_{i=1}^m (x_j^{(i)}-\mu_j)^2 </script>

<p>在高斯分布平面投影上椭圆变成了圆。</p>

<p>假如不对<script type="math/tex">\Sigma</script>做限制，我们必须在<script type="math/tex">m \geq n+1</script>的条件下才能保证<script type="math/tex">\Sigma</script>不是一个奇异阵，在上面的约束下，只需要<script type="math/tex">m \geq 2</script>就能保证非奇异。</p>

<p>但上述的假设太强，意味着特征之间完全相互独立，假如我们想要挖掘数据内部的关系时，就需要使用到因子分析模型。</p>

<h2 id="section">边缘和条件高斯分布</h2>
<p>在描述因子分析之前，我们先来讨论一下如何找到联合多元高斯分布的条件分布和边缘分布。</p>

<p>假定我们有一个随机变量：</p>

<script type="math/tex; mode=display">
x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
</script>

<p>这里<script type="math/tex">x_1 \in \mathbb{R}^r, x_2 \in \mathbb{R}^s, \Sigma_{11} \in \mathbb{R}^{r\times r}, \Sigma_{12} \in \mathbb{R}^{r \times s}</script> 假定 <script type="math/tex"> x \sim \mathcal{N} (\mu, \Sigma) </script>，有：</p>

<script type="math/tex; mode=display">% <![CDATA[
 \mu = \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix}, 
\Sigma = \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{bmatrix}  %]]></script>

<p><script type="math/tex">x_1</script> 和<script type="math/tex">x_2</script>被称为联合多元分布，那么<script type="math/tex">x_1</script>的边缘分布是什么？很容易可以看到<script type="math/tex">E[x_1]=\mu_1</script>, <script type="math/tex">Cov(x_1) = E[(x_1-\mu_1)(x_1-\mu_1)]=\Sigma_{11}</script>
。因为根据协方差的定义：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
Cov(x) &= \Sigma \\
&= \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22}
    \end{bmatrix} \\
&= E[(x-\mu)(x-\mu)^T] \\
&= E[\begin{pmatrix} x_1-\mu_1 \\ x_2-\mu_2 \end{pmatrix}
{\begin{pmatrix} x_1-\mu_1 \\ x_2-\mu_2 \end{pmatrix}}^T] \\
&= E \begin{pmatrix} (x_1-\mu_1)(x_1-\mu_1)^T (x_1-\mu_1)(x_2-\mu_2)^T \\
(x_2 - \mu_2)(x_1 - \mu_1)^T (x_2-\mu_2)(x_2-\mu_2)^T \end{pmatrix}
\end{align}
 %]]></script>

<p>因此可以得出<script type="math/tex">x_1</script>的边缘分布是<script type="math/tex">x_1 \sim \mathcal{N} (\mu_1, \Sigma_{11})</script>。</p>

<p>下面再来考虑在<script type="math/tex">x_2</script>给定下<script type="math/tex">x_1</script>的条件分布。可以记作<script type="math/tex">x_1 \mid x_2 \sim \mathcal{N} (\mu_{1\mid 2}, \Sigma_{1 \mid 2})</script>，可以计算如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
\mu_{1 \mid 2} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1 \mid 2} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\end{align}
 %]]></script>

<h2 id="section-1">因子分析模型</h2>
<p>在因子分析模型中，我们定义(x,z)的联合分布如下，其中<script type="math/tex">z \in \mathbb{R}^k </script>是一个潜在随机变量：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
z & \sim \mathcal{N}(0, I) \\
x \mid z & \sim \mathcal{N} (\mu + \Lambda z, \Psi)
\end{align}
 %]]></script>

<p>其中向量<script type="math/tex">\mu \in \mathcal{R}^n </script>，矩阵 <script type="math/tex"> \Lambda \in \mathcal{R}^{n \times k} </script>， 对角阵<script type="math/tex">\Psi \in \mathcal{R}^{n \times n}</script>，k的取值一般都要小于n。</p>

<p>我们相当于把数据从k维映射到n维<script type="math/tex">\mu+ \Lambda z</script>，最后再填上一个噪音<script type="math/tex">\Psi</script>。上面的因子分析模型也可以表示成下面的形式：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
z & \sim \mathcal{N} (0, I) \\
\epsilon & \sim \mathcal{N} (0, \Psi) \\
x & = \mu + \Lambda z + \epsilon
\end{align}
 %]]></script>

<p>我们的随机变量z，x构成了一个联合高斯分布：</p>

<script type="math/tex; mode=display">
\begin{bmatrix} z \\ x \end{bmatrix} \sim \mathcal{N} (\mu_{zx}, \Sigma)
</script>

<p>下面来找到<script type="math/tex">\mu_{zx}</script>和<script type="math/tex">\Sigma</script>。</p>

<p>容易直到<script type="math/tex">E[z]=0</script>，因为z满足标准正态分布。<script type="math/tex">E[x]=\mu</script>可有下式求解：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
E[x] &= E[\mu+ \Psi z + \epsilon] \\
&= \mu + \Psi E[z] + E[\epsilon] \\
&= \mu
\end{align}
 %]]></script>

<p>因此可以得到<script type="math/tex">\mu_{zx}</script>:</p>

<script type="math/tex; mode=display">\mu_{zx} =
\begin{bmatrix}
\overrightarrow{0} \\
\mu
\end{bmatrix}
</script>

<p>下面继续计算<script type="math/tex">\Sigma</script>，因为<script type="math/tex">\Sigma_{zz} = Cov(z) = I</script>，</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
\Sigma_{zx} &= E[(z - E[z])(x - E[x])^T] \\
&= E[z (\mu + \Lambda z + \epsilon - \mu)^T ] \\
&= E[zz^T] \Lambda^T + E [z \epsilon^T] \\
&= \Lambda^T
\end{align}
 %]]></script>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
\Sigma_{xx} &= E[(x - E[x])(x - E[x])^T] \\
&= E[(\mu + \Lambda z + \epsilon - \mu)(\mu + \Lambda z + \epsilon - \mu)^T ] \\
&= E[ \Lambda z z^T \Lambda^T + \epsilon z^T \Lambda^T + \Lambda z \epsilon^T + \epsilon \epsilon^T] \\
&= \Lambda E[z z^t] \Lambda^T + E [\epsilon \epsilon^T] \\
\Lambda \Lambda^T + \Psi
\end{align}
 %]]></script>

<p>最终我们得到联合分布如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{bmatrix}
z \\ x
\end{bmatrix}
\sim \mathcal{N} \left (
\begin{bmatrix}
\overrightarrow{0} \\ \mu
\end{bmatrix},
\begin{bmatrix}
I & \Lambda^T \\
\Lambda & \Lambda \Lambda^T + \Psi
\end{bmatrix}
\right)
 %]]></script>

<p>x的边缘分布是<script type="math/tex">x \sim \mathcal{N} (\mu, \Lambda \Lambda^T + \Psi) </script>，因此可以得出其最大似然函数的表达式：</p>

<script type="math/tex; mode=display">\ell (\mu, \Lambda, \Psi) = \log \prod_{i=1}^m \frac {1} {2\pi)^{n/2}
{| \Lambda\Lambda^T + \Psi |}^{1/2} } \exp \left( - \frac{1}{2}
(x^{(i)}-\mu)^T (\Lambda \Lambda^T + \Psi)^{-1} (x^{(i)} - \mu) \right) </script>

<p>对于上述的最大似然函数估计，同样的无法直接求解，需要用最大期望算法来解决。</p>

<h2 id="section-2">因子分析的最大期望算法</h2>

<p>在E步，我们需要计算<script type="math/tex">Q_i(z^{(i)}) = p(z^{(i)} \mid x^{(i)}; \mu, \Lambda, \Psi)。根据前面条件分布的公式，我们知道</script> z^{(i)} \mid x^{(i)}; \mu, \Lambda, \Psi \sim \mathcal{N} (\mu<em>{z^{(i)} \mid x^{(i)}}, \Sigma</em>{z^{(i)} \mid x^{(i)}})，其中：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align}
\mu_{z^{(i)} \mid x^{(i)}} &= \Lambda^T (\Lambda\Lambda^T + \Psi)^{-1} (x^{(i)} - \mu) \\
\Sigma_{z^{(i)} \mid x^{(i)}} &= I - \Lambda^T (\Lambda\Lambda^T + \Psi)^{-1} \Lambda
\end{align}
 %]]></script>

<p>后面的推导偷懒不写了~一句话就是用EM算法去求解，感觉更多的是考验数学水平。</p>

