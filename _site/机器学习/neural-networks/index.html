<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.9.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="zh" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>神经网络 - 木公的博客-Anyinlover Blog</title>




<meta name="description" content="简介在这一章我们描述了一类学习方法，它们分别在统计和人工智能领域独立发展过，但模型却是一致的。其中的核心思想就是将输入的线性组合作为特征，将目标建模为这些特征的非线性函数。这种方法在很多领域广泛应用。我们首先介绍投影寻踪模型，然后再介绍神经网络模型。">




<meta name="author" content="Anyinlover">

<meta property="og:locale" content="zh_CN">
<meta property="og:site_name" content="木公的博客-Anyinlover Blog">
<meta property="og:title" content="神经网络">


  <link rel="canonical" href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/neural-networks/">
  <meta property="og:url" content="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/neural-networks/">



  <meta property="og:description" content="简介在这一章我们描述了一类学习方法，它们分别在统计和人工智能领域独立发展过，但模型却是一致的。其中的核心思想就是将输入的线性组合作为特征，将目标建模为这些特征的非线性函数。这种方法在很多领域广泛应用。我们首先介绍投影寻踪模型，然后再介绍神经网络模型。">

















  

  



  <meta property="og:image" content="http://localhost:4000/img/sunrise.jpg">



  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2016-05-31T00:00:00+08:00">






  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Organization",
      "url": "http://localhost:4000",
      "logo": "http://localhost:4000/img/tree.jpg"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Anyinlover",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>







<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="木公的博客-Anyinlover Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/">木公的博客-Anyinlover Blog</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about" >关于</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/year-archive/" >博文</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/categories/" >类别</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/tags/" >标签</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle" type="button">
          <span class="visually-hidden">切换菜单</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style=" background-image: url('http://localhost:4000/img/sunrise.jpg');"
>
  
    <div class="wrapper">
      <h1 class="page__title" itemprop="headline">
        
          神经网络

        
      </h1>
      
      
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="http://localhost:4000/img/morning.jpg" alt="Anyinlover" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Anyinlover</h3>
    
    
      <p class="author__bio" itemprop="description">
        未经审视的人生是不值得过的
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">关注</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Xi'an</span>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://github.com/anyinlover" itemprop="sameAs">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://www.weibo.com/2663254313" itemprop="sameAs">
            <i class="fab fa-fw fa-weibo" aria-hidden="true"></i> Weibo
          </a>
        </li>
      

      

      

      

        <li>
          <a href="https://www.douban.com/people/48573787/" itemprop="sameAs">
            <span class="fa-layers fa-fw">
              <i class="fas fa-circle"></i>
              <span class="fa-layers-text fa-inverse" data-fa-transform="shrink-4">豆</span>
            </span>
            Douban
          </a>
        </li>
      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="神经网络">
    <meta itemprop="description" content="简介在这一章我们描述了一类学习方法，它们分别在统计和人工智能领域独立发展过，但模型却是一致的。其中的核心思想就是将输入的线性组合作为特征，将目标建模为这些特征的非线性函数。这种方法在很多领域广泛应用。我们首先介绍投影寻踪模型，然后再介绍神经网络模型。">
    <meta itemprop="datePublished" content="May 31, 2016">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目录</h4></header>
              <ul class="toc__menu">
  <li><a href="#简介">简介</a></li>
  <li><a href="#投影寻踪回归">投影寻踪回归</a></li>
  <li><a href="#神经网络">神经网络</a></li>
  <li><a href="#神经网络拟合">神经网络拟合</a></li>
  <li><a href="#神经网络训练的讨论">神经网络训练的讨论</a>
    <ul>
      <li><a href="#初始值">初始值</a></li>
      <li><a href="#过拟合">过拟合</a></li>
      <li><a href="#输入范围">输入范围</a></li>
      <li><a href="#隐藏单元和层的数目">隐藏单元和层的数目</a></li>
      <li><a href="#多极小值">多极小值</a></li>
    </ul>
  </li>
</ul>
            </nav>
          </aside>
        
        <h2 id="简介">简介</h2>
<p>在这一章我们描述了一类学习方法，它们分别在统计和人工智能领域独立发展过，但模型却是一致的。其中的核心思想就是将输入的线性组合作为特征，将目标建模为这些特征的非线性函数。这种方法在很多领域广泛应用。我们首先介绍投影寻踪模型，然后再介绍神经网络模型。</p>

<h2 id="投影寻踪回归">投影寻踪回归</h2>
<p>假设我们有一个输入向量X长度为p，和一个目标值Y。令<script type="math/tex">\omega_m, m=1,2,\cdots,M</script>是一组长度为p的向量构成的未知参数，则投影寻踪回归模型具有以下的形式：</p>

<script type="math/tex; mode=display">f(X) = \sum_{m=1}^M g_m(\omega_m^T X)</script>

<p>这是一个加性模型，但特征是<script type="math/tex">V_m = \omega_m^T X</script>而不是输入本身。函数<script type="math/tex">g_m</script>是非指定的。</p>

<p>函数<script type="math/tex">g_m(\omega_m^T X)</script>被称为<script type="math/tex">\mathbb{R}^p</script>的桥函数。其只在向量<script type="math/tex">\omega_m</script>方向变化。<script type="math/tex">V_m = \omega_m^T X</script>相当于<script type="math/tex">X</script>在单位向量<script type="math/tex">\omega_m</script>方向上的投射。<script type="math/tex">\omega_m</script>是需要模型拟合的参数。</p>

<p>PPR模型主要用于分类，对于产生解释性模型比较无力，只有<script type="math/tex">M=1</script>是个例外，相当于线性回归的更一般化。</p>

<p>给定训练样本<script type="math/tex">(x_i,y_i), i=1,2,\cdots,N</script>，如何来拟合PPR模型？令损失函数为：</p>

<script type="math/tex; mode=display">\sum_{i=1}^N [y_i - \sum_{m=1}^M g_m (\omega_m^T x_i)]^2</script>

<p>和其他平滑问题一样，需要为<script type="math/tex">g_m</script>添加复杂的限制来避免过拟合。</p>

<p>考虑<script type="math/tex">M=1</script>的情况，给定方向向量<script type="math/tex">\omega</script>，我们得到<script type="math/tex">v_i = \omega^T x_i</script>，然后通过散点平滑方法来得到g的估计。</p>

<p>另一方面，给定g后，需要最小化<script type="math/tex">\omega</script>。高斯牛顿搜索可以解决这个问题，通过将二次导舍弃，我们可以近似得到：</p>

<script type="math/tex; mode=display">g(\omega^T x_i) \approx g(\omega_{old}^T x_i) + g' (\omega_{old}^T x_i)
(\omega - \omega_{old})^T x_i</script>

<p>因此可以近似得到：</p>

<script type="math/tex; mode=display">\sum_{i=1}^N [y_i - \sum_{m=1}^M g (\omega^T x_i)]^2 \approx \sum_{i=1}^N g' (\omega_{old}^T x_i)^2 [(\omega_{old}^T + \frac{y_i - g (\omega_{old}^T x_i)}{g' (\omega_{old}^T x_i)}) - \omega^T x_i]^2</script>

<p>通过对于上面两步的交替迭代，直到拟合。</p>

<h2 id="神经网络">神经网络</h2>
<p>神经网络被传得神神道道，其实只不过是一个非线性统计模型。</p>

<p>一个典型的神经网络是一个两层的回归或分类模型。作为回归模型时上层只有一个<script type="math/tex">Y_1</script>。对于k类分类问题，上层有K个单元，第k个单元代表第k类的可能性，用<script type="math/tex">Y_k, k=1,\cdots,K</script>来衡量，每一个都是0-1之间的取值。</p>

<p>提取的特征<script type="math/tex">Z_m</script>通过对输入进行线性组合构造成，目标值<script type="math/tex">Y_k</script>则是<script type="math/tex">Z_m</script>的函数：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
Z_m &= \sigma(\alpha_{0m} + \alpha_m^T X), m = 1,\cdots,M, \\
T_k &= \beta_{0k} + \beta_k^T Z, k=1,\cdots,K, \\
f_k(X) &= g_k(T), k=1,\cdots,K
\end{align} %]]></script>

<p>激励函数<script type="math/tex">\sigma(v)</script>常常选择S型函数<script type="math/tex">\sigma(v)=1/(1+e^{-v})</script>，有时候高斯径向基函数也被用作<script type="math/tex">\sigma(v)</script>，这时神经网络被称为径向基网络。</p>

<p>从上面的公式中可以看出，对每个隐藏层和输出层，都添加了额外的偏差<script type="math/tex">\alpha_{0m}, \beta_{0k}</script>。</p>

<p>输出函数<script type="math/tex">g_k(T)</script>允许对输出T做最后的转换。对于回归，一般都选择本身<script type="math/tex">g_k(T) = T_k</script>，对于K类分类，则选择softmax函数：</p>

<script type="math/tex; mode=display">g_k(T) = \frac {e^{T_k}} {\sum_{l=1}^K e^{T_l}}</script>

<p>如果把<script type="math/tex">Z_m</script>看做原始输入X的基本扩展，那么神经网络就是一个标准的线性模型。</p>

<p>如果<script type="math/tex">\sigma</script>也是个恒等函数，那模型也可以看做针对输入的线性模型。因此神经网络可以被视为对线性模型的非线性泛化，这个结论对回归和分类都使用。</p>

<p>注意到一层隐含层的神经网络模型和上一节中的投影寻踪模型具有一致的形式。</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
g_m(\omega_m^T X) &= \beta_m \sigma(\alpha_{0m} + \alpha_m^T X) \\
&= \beta_m \sigma(\alpha_{0m} + \| \alpha_m \| (\omega_m^T X))
\end{align} %]]></script>

<h2 id="神经网络拟合">神经网络拟合</h2>
<p>神经网络的未知参数，常常被称为权重。</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\{\alpha_{0m}, \alpha_m; m =1,2,\cdots,M\} \quad M(p+1) weights, &
\{\beta_{0k}, \beta_k; k =1,2,\cdots,K\}  \quad K(M+1) weights
\end{align} %]]></script>

<p>对于回归来说，使用平方和误差作为误差函数：</p>

<script type="math/tex; mode=display">R(\theta) = \sum_{k=1}^K sum_{i=1}^N (y_{ik} - f_k(x_i))^2</script>

<p>对于分类而言，使用平方和误差或者互熵：</p>

<script type="math/tex; mode=display">R(\theta) = - \sum_{i=1}^N \sum_{k=1}^K y_{ik} \log f_k(x_i)</script>

<p>对应的分类就是 <script type="math/tex">G(x) = argmax_k f_k(x)</script>。使用softmax激励函数和互熵误差函数，神经网络在隐藏层就是一个逻辑回归模型，所有参数可以通过最大似然性得到。</p>

<p>标准的最小化<script type="math/tex">R(\theta)</script>做法是通过梯度递减，在这里被称为反向传播算法。</p>

<p>令<script type="math/tex">z_{mi} = \sigma (\alpha_{0m} + \alpha_m^T x_i)</script>，令<script type="math/tex">z_i = (z_{1i}, z_{2i}, \cdots, z_{Mi})</script>。对于平方和误差而言，由于：</p>

<script type="math/tex; mode=display">R(\theta) = \sum_{i=1}^N R_i = \sum_{i=1}^N \sum_{k=1}^K (y_{ik} - f_k(x_i))^2</script>

<p>其导数为：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial R_i}{\partial \beta_{km}} &= -2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i) z_{mi} \\
\frac{\partial R_i}{\partial \alpha_{ml}} &= -\sum_{k=1}^K 2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i) \beta_{km} \sigma' (\alpha_m^T x_i) x_{il}
\end{align} %]]></script>

<p>得到导数后，根据梯度下降算法：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\beta_{km}^{(r+1)} &= \beta_{km}^{(r)} - \gamma_r \sum_{i=1}^N \frac {\partial R_i} {\partial \beta_{km}^{(r)}} \\
\alpha_{ml}^{(r+1)} &= \alpha_{ml}^{(r)} - \gamma_r \sum_{i=1}^N \frac {\partial R_i} {\partial \alpha_{ml}^{(r)}}
\end{align} %]]></script>

<p>其中<script type="math/tex">\gamma_r</script>是学习率。</p>

<p>将导数记为：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial R_i}{\partial \beta_{km}} &= \delta_{ki} z_{mi} \\
\frac{\partial R_i}{\partial \alpha_{ml}} &= s_{mi} x_{il}
\end{align} %]]></script>

<p>其中<script type="math/tex">\delta_{ki},s_{mi}</script>是模型在输出层和隐藏层的误差。根据定义，它们满足以下关系：</p>

<script type="math/tex; mode=display">s_{mi} = \sigma' (\alpha_m^T x_i) \sum_{k=1}^K \beta_{km} \delta_{ki}</script>

<p>上面这个式子被称为反向传播等式。利用这个，参数更新可以通过两步走。正向走时，当前权重固定，预测值<script type="math/tex">\hat{f}_k (x_i)</script>计算得到，反向走时，误差<script type="math/tex">\delta_{ki}</script>计算得到，进一步得到<script type="math/tex">s_{mi}</script>。然后再去更新参数。这个算法也被称为反向传播算法。</p>

<p>反向传播算法的优点在于其简单和本地属性。但它的速度比较慢，牛顿方法同样不适用（R的海森矩阵计算量大）。更好的拟合方法是共轭梯度和变度算法。</p>

<h2 id="神经网络训练的讨论">神经网络训练的讨论</h2>

<h3 id="初始值">初始值</h3>

<h3 id="过拟合">过拟合</h3>

<h3 id="输入范围">输入范围</h3>

<h3 id="隐藏单元和层的数目">隐藏单元和层的数目</h3>

<h3 id="多极小值">多极小值</h3>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 标签: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#esl" class="page__taxonomy-item" rel="tag">ESL</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95" class="page__taxonomy-item" rel="tag">机器学习算法</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 分类: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/categories/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" class="page__taxonomy-item" rel="tag">机器学习</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新时间:</strong> <time datetime="2016-05-31T00:00:00+08:00">May 31, 2016</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/tree/" class="pagination--pager" title="树
">向前</a>
    
    
      <a href="http://localhost:4000/%E5%AE%9E%E8%B7%B5/sql-exercise/" class="pagination--pager" title="sql练习
">向后</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">猜您还喜欢</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E5%B7%A5%E5%85%B7/%E5%8D%9A%E5%AE%A2%E9%87%8D%E5%BB%BA/" rel="permalink">博客重建
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">今天花了整整一天的时候把我的博客重建起来了，主要是换了一个主题，然后剩下的时候就一直在折腾了。这次用了一个很受欢迎的minimal-mistakes，搞下来才发现它为啥叫迷你了，自己要设置的东西太多了！

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%84%8F%E4%B9%89/" rel="permalink">人生的意义
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">人生的意义

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E5%B7%A5%E5%85%B7/shadowsocksr/" rel="permalink">shadowsocksR
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">时代在发展，shadowsocks源作者已经被请去喝茶了，现在更流行的一个叫shadowsocksR加强版，感谢两位作者。这里也趁着换VPS的同时新装了一个shadowsocksR。

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E7%AC%94%E8%AE%B0/ruby-gem-bundler/" rel="permalink">ruby &amp; gem &amp; bundler
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">ruby

</p>
  </article>
</div>
        
      </div>
    </div>
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap">
  <input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  <div id="results" class="results"></div>
</div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>关注:</strong></li>
    
    
    
    
      <li><a href="https://github.com/anyinlover"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Anyinlover. 技术来自于 <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="http://localhost:4000/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.0.2/js/all.js"></script>



  
  
  <script defer src="http://localhost:4000/assets/js/lunr/lunr.min.js"></script>
  <script defer src="http://localhost:4000/assets/js/lunr/lunr-store.js"></script>
  <script defer src="http://localhost:4000/assets/js/lunr/lunr-en.js"></script>



<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>





    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/neural-networks/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/neural-networks"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://anyinlover.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



  </body>
</html>