<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.9.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="zh" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>线性回归 - 木公的博客-Anyinlover Blog</title>




<meta name="description" content="几乎所有的机器学习书籍都以线性回归为起点，这是有道理的。第一，线性回归比较容易入门，第二，线性回归是后续很多现代算法的基础，第三，线性回归是一种应用非常广泛的算法。">




<meta name="author" content="Anyinlover">

<meta property="og:locale" content="zh_CN">
<meta property="og:site_name" content="木公的博客-Anyinlover Blog">
<meta property="og:title" content="线性回归">


  <link rel="canonical" href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/linear-reg/">
  <meta property="og:url" content="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/linear-reg/">



  <meta property="og:description" content="几乎所有的机器学习书籍都以线性回归为起点，这是有道理的。第一，线性回归比较容易入门，第二，线性回归是后续很多现代算法的基础，第三，线性回归是一种应用非常广泛的算法。">

















  

  



  <meta property="og:image" content="http://localhost:4000/img/sunrise.jpg">



  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2016-04-10T00:00:00+08:00">






  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Organization",
      "url": "http://localhost:4000",
      "logo": "http://localhost:4000/img/tree.jpg"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Anyinlover",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>







<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="木公的博客-Anyinlover Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/">木公的博客-Anyinlover Blog</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about" >关于</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/year-archive/" >博文</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/categories/" >类别</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/tags/" >标签</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle" type="button">
          <span class="visually-hidden">切换菜单</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style=" background-image: url('http://localhost:4000/img/sunrise.jpg');"
>
  
    <div class="wrapper">
      <h1 class="page__title" itemprop="headline">
        
          线性回归

        
      </h1>
      
      
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="http://localhost:4000/img/morning.jpg" alt="Anyinlover" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Anyinlover</h3>
    
    
      <p class="author__bio" itemprop="description">
        未经审视的人生是不值得过的
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">关注</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Xi'an</span>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://github.com/anyinlover" itemprop="sameAs">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://www.weibo.com/2663254313" itemprop="sameAs">
            <i class="fab fa-fw fa-weibo" aria-hidden="true"></i> Weibo
          </a>
        </li>
      

      

      

      

        <li>
          <a href="https://www.douban.com/people/48573787/" itemprop="sameAs">
            <span class="fa-layers fa-fw">
              <i class="fas fa-circle"></i>
              <span class="fa-layers-text fa-inverse" data-fa-transform="shrink-4">豆</span>
            </span>
            Douban
          </a>
        </li>
      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="线性回归">
    <meta itemprop="description" content="几乎所有的机器学习书籍都以线性回归为起点，这是有道理的。第一，线性回归比较容易入门，第二，线性回归是后续很多现代算法的基础，第三，线性回归是一种应用非常广泛的算法。">
    <meta itemprop="datePublished" content="April 10, 2016">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 目录</h4></header>
              <ul class="toc__menu">
  <li><a href="#梯度下降法">梯度下降法</a></li>
  <li><a href="#标准方程法">标准方程法</a></li>
  <li><a href="#概率解释">概率解释</a></li>
  <li><a href="#局部加权线性回归">局部加权线性回归</a></li>
</ul>
            </nav>
          </aside>
        
        <p>几乎所有的机器学习书籍都以线性回归为起点，这是有道理的。第一，线性回归比较容易入门，第二，线性回归是后续很多现代算法的基础，第三，线性回归是一种应用非常广泛的算法。</p>

<p>简单线性回归的模型很简单，可以下面的公式表示：</p>

<script type="math/tex; mode=display">h(x)=\displaystyle\sum_{i=0}^{n} \theta_ix_i=\theta^Tx</script>

<p>其中<script type="math/tex">\theta</script>称为参数或权重。上式实现从X空间到Y空间的映射。</p>

<p>拟合程度的好坏可以用下面的函数表示：</p>

<script type="math/tex; mode=display">J(\theta)=\frac{1}{2}\displaystyle\sum_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)})^2</script>

<p><script type="math/tex">J(\theta)</script>被称为损失函数，这里的损失函数用估计值与实际值差的平方和来表示，是一种最常见的表示误差的方法。我们的目标就是使这个损失函数降到最小，实现最佳拟合。求最小二乘常用的有梯度下降法和举证计算法。</p>

<h2 id="梯度下降法">梯度下降法</h2>

<p>梯度下降法的本质就是用迭代的思想，每一次都沿着最陡的方向（梯度）下降一小步，最终到达最小值。注意梯度下降法本身只能求局部最优解，但由于线性回归的J是个凸二次函数，因此局部最小值就是全局最小值。</p>

<p>先对<script type="math/tex">\theta</script>给出一个原始猜测值（一般可以取0），然后执行下面的迭代，其中<script type="math/tex">\alpha</script>是个固定值，称为学习率：</p>

<script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)</script>

<p>对<script type="math/tex">J(\theta)</script>求偏导可得下式：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial}{\partial\theta_j}J(\theta)&=\frac{\partial}{\partial\theta_j}\frac{1}2(h_\theta(x)-y)^2 \\&=2\cdot\frac{1}2(h_\theta(x)-y)\cdot\frac{\partial}{\partial\theta_j}(h_\theta-y)\\&=(h_\theta(x)-y)\cdot\frac{\partial}{\partial\theta_j}(\displaystyle\sum_{i=0}^n \theta_ix_i-y)\\&=(h_\theta(x)-y)x_j
\end{align} %]]></script>

<p>所以有最终迭代的方程：</p>

<script type="math/tex; mode=display">\theta_j:=\theta_j+\alpha(y-h_\theta(x))x_j</script>

<p>直观理解，二次函数的导数就是个一次函数，沿着导数方向下降，就是上面这式子。</p>

<p>上述式子是在只有一个训练样本时的情况，实际肯定会有大量的训练样本。对于多个训练样本，可以有两种变式。
第一种方法叫批梯度下降，每一次迭代时，我把所有训练样本的误差都跑一遍，叠加后对<script type="math/tex">\theta</script>进行更新。</p>

<script type="math/tex; mode=display">\theta_j:=\theta_j+\alpha\sum_{i=1}^m(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}</script>

<p>另一种方法叫随机梯度下降，每跑一个样本，我就迭代一次。</p>

<script type="math/tex; mode=display">\text{for }i=1\text{ to }m:\\
\theta_j:=\theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}</script>

<p>显然随机梯度下降会比批梯度下降跑的快，由于每一次迭代都要计算所有样本，批梯度非常耗时。另一方面，随机梯度很可能无法达到最小值，而是在最小值左右徘徊。因此对大数据集我们倾向于选择随机梯度，而对于小数据集则选择批梯度。</p>

<h2 id="标准方程法">标准方程法</h2>

<p>对于损失函数最小值的求解，除了上面的梯度下降法，还可以用矩阵直接进行计算。但其过程涉及到很多的矩阵推导，需要具备较高的数学基础。这种算法的本质就是利用了函数最小值处导数等于0的性质。</p>

<p>把上面的损失函数向量化，就是下面的表达式：</p>

<script type="math/tex; mode=display">J(\theta)=\frac{1}2(X\theta-\overrightarrow{y})^T(X\theta-\overrightarrow{y})</script>

<p>将上面的损失函数对<script type="math/tex">\theta</script>求导，可以得到：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\nabla_{\theta}J(\theta)&=\nabla_{\theta}\frac{1}2(X\theta-\overrightarrow{y})^T(X\theta-\overrightarrow{y})\\
&=\frac{1}2\nabla_{\theta}(\theta^TX^TX\theta-\theta^TX^T\overrightarrow{y}-\overrightarrow{y}^TX\theta+\overrightarrow{y}^T\overrightarrow{y})\\
&=\frac{1}2\nabla_{\theta}tr(\theta^TX^TX\theta-\theta^TX^T\overrightarrow{y}-\overrightarrow{y}^TX\theta+\overrightarrow{y}^T\overrightarrow{y})\\
&=\frac{1}2\nabla_{\theta}(tr\theta^TX^TX\theta-2tr\overrightarrow{y}^TX\theta)\\
&=\frac{1}2(X^TX\theta+X^TX\theta-2X^T\overrightarrow{y}）\\
&=X^TX\theta-X^T\overrightarrow{y}
\end{align} %]]></script>

<p>上述推导利用了矩阵的迹及相关性质，另篇专述。</p>

<p>令等式等于0，可以得到：</p>

<script type="math/tex; mode=display">X^TX\theta=X^T\overrightarrow{y}</script>

<p>容易求出<script type="math/tex">\theta</script>：</p>

<script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^T\overrightarrow{y}</script>

<p>注意当训练集和特征值很多时，求矩阵的逆会很耗时，此时算法的性能不如前面的梯度下降法。</p>

<h2 id="概率解释">概率解释</h2>

<p>这一节从概率的角度出发，论证了为什么把最小二乘作为损失函数是令人信服的选择。个人觉得这是一个比较有趣的角度。</p>

<p>假设我们的模型估计值和y真实值存在一个偏差<script type="math/tex">\epsilon</script>，表示未被模型考虑的因素或者是随机的噪音。进一步假设<script type="math/tex">\epsilon^{(i)}</script>是独立同分布的，服从<script type="math/tex">\epsilon^{(i)}\sim\mathcal{N}(0,\sigma^2)</script>的高斯分布：</p>

<script type="math/tex; mode=display">p(\epsilon^{(i)})=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})</script>

<p>似然性函数等于：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
L(\theta)&=\prod_{i=1}^m p(y^{(i)}\mid x^{(i)};\theta) \\
&=\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})
\end{align} %]]></script>

<p>根据最大似然性准则，我们需要选择<script type="math/tex">\theta</script>使似然性函数取到最大值。</p>

<p>两边同取log函数，得到对数似然性函数：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\ell(\theta)&=\log{L(\theta)}\\
&=\log\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})\\
&=\sum_{i=1}^m \log\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})\\
&=m\log\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\displaystyle\sum_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)})^2
\end{align} %]]></script>

<p>可以看出为了让<script type="math/tex">\ell(\theta)</script>最大，必须让<script type="math/tex">\frac{1}{2}\displaystyle\sum_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)})^2</script>最小，这就是前面的损失函数<script type="math/tex">h(\theta)</script>。还可以发现<script type="math/tex">\theta</script>的取值和<script type="math/tex">\sigma</script>是无关的。</p>

<p>需要注意的是最小二乘并不是唯一合理的损失函数，最大似然性作为一种假设也不是推导损失函数的必要条件。我们还有其他合理的损失函数可以选择。</p>

<h2 id="局部加权线性回归">局部加权线性回归</h2>

<p>局部加权线性回归的本质在于考虑了预测样本，对于训练集中和预测样本相似的训练样本，给予其更高的权值。</p>

<p>局部加权线性回归修改了简单线性回归的损失函数，添加了一个权值函数<script type="math/tex">w^{(i)}</script>：</p>

<script type="math/tex; mode=display">h(\theta)=\frac{1}{2}\sum_{i=1}^{m}w^{(i)} (h_\theta(x^{(i)})-y^{(i)})^2</script>

<p>这个权值函数又是和预测样本相关联的，下面是一种标准的选择，x是预测样本的输入，<script type="math/tex">\tau</script>称为带宽，可以调整：</p>

<script type="math/tex; mode=display">w^{(i)}=\exp(-\frac{(x^{(i)}-x)^2}{2\tau^2})</script>

<p>局部加权线性回归显然是一种比简单线性回归优化的算法，但他也被称为非参数算法，因为模型参数会随着预测样本变化，因此需要每一次进行即时计算。</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 标签: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#ng%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97" class="page__taxonomy-item" rel="tag">Ng机器学习系列</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95" class="page__taxonomy-item" rel="tag">机器学习算法</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 分类: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/categories/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" class="page__taxonomy-item" rel="tag">机器学习</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 更新时间:</strong> <time datetime="2016-04-10T00:00:00+08:00">April 10, 2016</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="http://localhost:4000/%E5%B7%A5%E5%85%B7/Ipython/" class="pagination--pager" title="IPython Tutorial
">向前</a>
    
    
      <a href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/logistic-reg/" class="pagination--pager" title="逻辑回归
">向后</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">猜您还喜欢</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E5%B7%A5%E5%85%B7/%E5%8D%9A%E5%AE%A2%E9%87%8D%E5%BB%BA/" rel="permalink">博客重建
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">今天花了整整一天的时候把我的博客重建起来了，主要是换了一个主题，然后剩下的时候就一直在折腾了。这次用了一个很受欢迎的minimal-mistakes，搞下来才发现它为啥叫迷你了，自己要设置的东西太多了！

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%84%8F%E4%B9%89/" rel="permalink">人生的意义
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">人生的意义

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E5%B7%A5%E5%85%B7/shadowsocksr/" rel="permalink">shadowsocksR
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">时代在发展，shadowsocks源作者已经被请去喝茶了，现在更流行的一个叫shadowsocksR加强版，感谢两位作者。这里也趁着换VPS的同时新装了一个shadowsocksR。

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "http://localhost:4000/img/tree.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/%E7%AC%94%E8%AE%B0/ruby-gem-bundler/" rel="permalink">ruby &amp; gem &amp; bundler
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">ruby

</p>
  </article>
</div>
        
      </div>
    </div>
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap">
  <input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  <div id="results" class="results"></div>
</div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>关注:</strong></li>
    
    
    
    
      <li><a href="https://github.com/anyinlover"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Anyinlover. 技术来自于 <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="http://localhost:4000/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.0.2/js/all.js"></script>



  
  
  <script defer src="http://localhost:4000/assets/js/lunr/lunr.min.js"></script>
  <script defer src="http://localhost:4000/assets/js/lunr/lunr-store.js"></script>
  <script defer src="http://localhost:4000/assets/js/lunr/lunr-en.js"></script>



<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>





    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/linear-reg/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/linear-reg"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://anyinlover.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



  </body>
</html>